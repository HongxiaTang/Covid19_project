{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2ZHy4XxlNg4-"
   },
   "source": [
    "# <h3><center>Covid_19 project</center></h3>\n",
    "<h3><center>Le Hoang Viet, Antoine, Liang Hu, Hongxia TANG - M2 FTD</center></h3>\n",
    "## Structure\n",
    "\n",
    "### 1. Introduction \n",
    "### 2. Importing library\n",
    "### 3. Data collection\n",
    "   ####  3.1. Stock data collection\n",
    "   ####  3.2. Contextualweb news collection\n",
    "### 4. Data Analysis\n",
    "   #### 4.1. Function of data analysis\n",
    "   ##### 4.1.1. By each stock\n",
    "   ##### 4.1.2. By each group of news\n",
    "   #### 4.2. Analysis based only on news happended during the trading time.\n",
    "   ##### 4.2.1. CAR for each stock\n",
    "   ##### 4.2.1.1. CAR of positive news\n",
    "   ##### 4.2.1.2. CAR of negative news\n",
    "   ##### 4.2.1.3. CAR of neutral news\n",
    "   #### 4.2.2. CAR for poeitive, negative or neutral news\n",
    "   #### 4.2.3. CAR by goup of news\n",
    "### 5. Result summary\n",
    "### 6. Conclusion\n",
    "### Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gYqBRTfFMI4M"
   },
   "source": [
    "# 1. Introduction\n",
    "\n",
    "In this notebook, we try to find the release of related news about covid-19 treatment medicine have impact on the drug's stock price or not. \n",
    "\n",
    "## 1.1. Data: \n",
    "**News data**: We tried to get news through NewSearchApi from 2020-01-01 to 2020-05-01, for the listed 7 different drug's news: **1. Nicotine** (3 news).  **2. Novavax**(5 news). **3. Galidesivir**(2 news). **4. AbbVie**(6 news). **5. Remdesivir**(20 news). **6.Chloroquine**(40 news). **7. Regeneron**(6 news). The filtered news are in the covid19-combined news spreadsheet. \n",
    "\n",
    "**Stock data**: We use two types of data. 1. tabacco companies stocks: 'mo','bats','rai','sdi','tpb','japaf','ctobf','sndvf','bti','btaff'. 2. pharmacy companies stocks: 'gild','jnj','pfe','abbv','mrk','abt','spy','nvax','sny','regn','bcrx'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mVX4Bz3ceoET"
   },
   "source": [
    "# 2. Importing library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 574
    },
    "colab_type": "code",
    "id": "Q9YJVtTL5QrO",
    "outputId": "1d275aec-2ccf-45b6-9f23-0aaf4ba9943d"
   },
   "outputs": [],
   "source": [
    "!pip install gspread-pandas\n",
    "!pip3 install pymongo[srv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install google-colab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /Users/susie/anaconda3/lib/python3.7/site-packages (2.21.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/susie/anaconda3/lib/python3.7/site-packages (from requests) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/susie/anaconda3/lib/python3.7/site-packages (from requests) (2.8)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /Users/susie/anaconda3/lib/python3.7/site-packages (from requests) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/susie/anaconda3/lib/python3.7/site-packages (from requests) (2020.4.5.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "om6PG79bLATW",
    "outputId": "d2e338aa-3d5e-4b6c-b635-93c89692786e"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "Rrk82qgn3oSc",
    "outputId": "88136d60-dd77-47bc-dd0e-41f74f5b6a7b"
   },
   "outputs": [],
   "source": [
    "import urllib3\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime as dt\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "import copy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "\n",
    "\n",
    "from datetime import timedelta\n",
    "from pymongo import MongoClient\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import statsmodels.formula.api as smf\n",
    "# from statsmodels.tsa.arima_model import ARIMA\n",
    "# from statsmodels.graphics.tsaplots import plot_acf\n",
    "# from statsmodels.graphics.tsaplots import plot_pacf\n",
    "# from statsmodels.tsa.stattools import adfuller\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# from statsmodels.tsa.api import VAR\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/content/drive/My Drive/Alternance/S2 Thomas project Covid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G35XLBm-pgMZ"
   },
   "source": [
    "# 3. Data collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tCsMDEzBrv-V"
   },
   "source": [
    "## 3.1. Stock data collection\n",
    "We use tiingo api to get our two types of stock data. As we introduced before, two types of companies are collected by us, 10 tobacco's company stock and and 11 pharmacy stock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BaIQYgYMrzs5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'requests' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-e5ad40169f53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mdb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Tobacco'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mstocki\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtobacco\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mrequestResponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"https://api.tiingo.com/iex/{}/prices?startDate=2019-01-02&resampleFreq=5min&token={}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstocki\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mdata_json\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequestResponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson_normalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_json\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'requests' is not defined"
     ]
    }
   ],
   "source": [
    "client = MongoClient('mongodb+srv://<account>:<password>@cluster0-sqhg2.mongodb.net/test?retryWrites=true&w=majority')\n",
    "token='[INSERT TIINGO API TOKEN]'\n",
    "headers = {\n",
    "    'Content-Type': 'application/json'\n",
    "}\n",
    "\n",
    "tobacco=['mo','bats','rai','sdi','tpb','japaf','ctobf','sndvf','bti','btaff']\n",
    "         \n",
    "pharma=['gild','jnj','pfe','abbv','mrk','abt','spy','nvax','sny','regn','bcrx']\n",
    "\n",
    "db=client['Tobacco']\n",
    "for stocki in tqdm(tobacco):\n",
    "    requestResponse = requests.get(\"https://api.tiingo.com/iex/{}/prices?startDate=2019-01-02&resampleFreq=5min&token={}\".format(stocki,token), headers=headers)\n",
    "    data_json=requestResponse.json()\n",
    "    data=json_normalize(data_json)\n",
    "    data.to_csv('{}.csv'.format(stocki),index=False)\n",
    "    for element in data_json:\n",
    "        insert_element = {\"TimeStamp\": element[\"date\"], \n",
    "                          \"close\": element[\"close\"], \n",
    "                          \"high\": element[\"high\"], \n",
    "                          \"low\": element[\"low\"],\n",
    "                          \"open\": element[\"open\"],\n",
    "                          }\n",
    "        try:\n",
    "            result = db['{}'.format(stocki)].insert_one(insert_element)\n",
    "        except:\n",
    "            break\n",
    "\n",
    "db=client['Pharma']\n",
    "for stocki in tqdm(pharma):\n",
    "    requestResponse = requests.get(\"https://api.tiingo.com/iex/{}/prices?startDate=2019-01-02&resampleFreq=5min&token={}\".format(stocki,token), headers=headers)\n",
    "    data_json=requestResponse.json()\n",
    "    data=json_normalize(data_json)\n",
    "    data.to_csv('{}.csv'.format(stocki),index=False)\n",
    "    for element in data_json:\n",
    "            insert_element = {\"TimeStamp\": element[\"date\"], \n",
    "                              \"close\": element[\"close\"], \n",
    "                              \"high\": element[\"high\"], \n",
    "                              \"low\": element[\"low\"],\n",
    "                              \"open\": element[\"open\"],\n",
    "                              }\n",
    "            try:\n",
    "                result = db['{}'.format(stocki)].insert_one(insert_element)\n",
    "            except:\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kl1nnpqEs1Pg"
   },
   "source": [
    "## 3.2. Contextualweb news collection\n",
    "Here we use NewsSearchAPI to collect our related news from 2020-01-01 to 2020-05-05. And then we manually check every news in our spreadsheet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nDeOH9_Zs3aJ"
   },
   "outputs": [],
   "source": [
    "db=client['Contextualweb']\n",
    "\n",
    "url = \"https://contextualwebsearch-websearch-v1.p.rapidapi.com/api/Search/NewsSearchAPI\"\n",
    "\n",
    "query='(tobacco or nicotine) and covid-19'\n",
    "\n",
    "for pgnum in tqdm(range(1,7)):\n",
    "    querystring = {\"fromPublishedDate\":\"01-01-2020\",\"toPublishedDate\":\"05-05-2020\",\"autoCorrect\":\"false\",\"pageNumber\":\"{}\".format(pgnum),\"pageSize\":\"50\",\"q\":\"{}\".format(query),\"safeSearch\":\"false\"}\n",
    "\n",
    "    headers = {\n",
    "        'x-rapidapi-host': \"contextualwebsearch-websearch-v1.p.rapidapi.com\",\n",
    "        'x-rapidapi-key': \"[INSERT RAPIDAPI API TOKEN HERE]\"\n",
    "        }\n",
    "#     try:\n",
    "    response = requests.request(\"GET\", url, headers=headers, params=querystring)\n",
    "    data=response.json()\n",
    "    for element in data[\"value\"]:\n",
    "        insert_element = {\"Title\": element[\"title\"], \n",
    "                          \"TimeStamp\": element[\"datePublished\"], \n",
    "                          \"Provider\": element[\"provider\"][\"name\"], \n",
    "                          \"URL\": element[\"url\"], \n",
    "                          \"Description\": element[\"description\"],\n",
    "                          \"Content\": element[\"body\"],\n",
    "                          \"Keywords\": element[\"keywords\"], \n",
    "                          \"Language\": element[\"language\"]\n",
    "                         }\n",
    "#         print(insert_element)\n",
    "        try:\n",
    "            result = db['{}'.format(query)].insert_one(insert_element)\n",
    "        except:\n",
    "            continue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2sjI-XXDer4F"
   },
   "source": [
    "# 4. Data analysis\n",
    "## 4.1. Function for data analysis\n",
    "Here we make different functions to analyse the relationship between stock return and news release in different ways."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r20KV0Tqfwyg"
   },
   "source": [
    "## 4.1.1. By each stock\n",
    "We categorize our news into 3 different types. **Positive**(the release of news have pisitive impact on stock return). **Negative**(the release of news have negative impact on stock return). **Neutral**(the release of news have no impact on stock return)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CaQXr1jN3tl1"
   },
   "outputs": [],
   "source": [
    "def get_CAR(begin_time,end_time,symbol,local_news=True,time_before=20,time_after=20,intra_only=False):\n",
    "  stock_twits_symbol_list=['GILD','REGN','ABBV','ABT','BCRX','BTI','PM','MO','TPB','NVAX','SNY']\n",
    "  stock_data_list=['gild','regn','abbv','abt','bcrx','bti','pm','mo','tpb','nvax','sny']\n",
    "  news_file_list=['remdesivir','regeneron','abbv','chloroquine','Biocryst','tobacco','tobacco','tobacco','tobacco','nvax','chloroquine']\n",
    "  \n",
    "  news=pd.read_csv('data/{}_news.csv'.format(news_file_list[stock_twits_symbol_list.index(symbol)]))\n",
    "  news.set_index('TimeStamp',inplace=True)\n",
    "  news.index=pd.to_datetime(news.index)\n",
    "  news_pos=news[(news['Sent']==1)&(news['US']==local_news)].resample('5Min').count()\n",
    "  news_neg=news[(news['Sent']==-1)&(news['US']==local_news)].resample('5Min').count()\n",
    "  news_neu=news[(news['Sent']==0)&(news['US']==local_news)].resample('5Min').count()\n",
    "  news=news.resample('5Min').count()\n",
    "\n",
    "  price=pd.read_csv('data/{}.csv'.format(stock_data_list[stock_twits_symbol_list.index(symbol)]))\n",
    "  price.date=pd.to_datetime(price.date)\n",
    "  price.set_index('date',inplace=True)\n",
    "  price.index=price.index.tz_localize(None)\n",
    "  price['return']=(price.close-price.close.shift(1))/price.close.shift(1)\n",
    "  price_fill=price['return'].resample('5Min').asfreq(fill_value=0).to_frame()\n",
    "\n",
    "  index_df=pd.read_csv('data/spy.csv')\n",
    "  index_df.date=pd.to_datetime(index_df.date)\n",
    "  index_df.set_index('date',inplace=True)\n",
    "  index_df.index=index_df.index.tz_localize(None)\n",
    "\n",
    "  index_filled=index_df['close'].resample('5Min').ffill().to_frame()\n",
    "  index_filled['return']=(index_filled.close-index_filled.close.shift(1))/index_filled.close.shift(1)\n",
    "\n",
    "  temp=price_fill['return'].to_frame()\n",
    "\n",
    "  df=temp[(temp.index>=begin_time) & (temp.index<=end_time) ]\n",
    "  df['news'] = df.index.to_series().map(news['Title'])\n",
    "  df['news_pos'] = df.index.to_series().map(news_pos['Title'])\n",
    "  df['news_neg'] = df.index.to_series().map(news_neg['Title'])\n",
    "  df['news_neu'] = df.index.to_series().map(news_neu['Title'])\n",
    "\n",
    "\n",
    "  df.fillna(0,inplace=True)\n",
    "  \n",
    "  df['ret_index']=df.index.to_series().map(index_filled['return'])\n",
    "  df.dropna(inplace=True)\n",
    "\n",
    "  Y = df['return']\n",
    "  X = df['ret_index']\n",
    "  X = sm.add_constant(X)\n",
    "  model = sm.OLS(Y,X)\n",
    "  results = model.fit()\n",
    "  df['exp_ret']=results.params[0]+results.params[1]*df['ret_index']\n",
    "  df['AR']=df['return']-df['exp_ret']\n",
    "\n",
    "  CAR_pos=[]\n",
    "  CAR_neg=[]\n",
    "  CAR_neu=[]\n",
    "\n",
    "  AR_list=df['AR'].values\n",
    "  news_pos_list=df['news_pos'].values\n",
    "  news_neg_list=df['news_neg'].values\n",
    "  news_neu_list=df['news_neu'].values\n",
    "\n",
    "  ret_list=df['return'].values\n",
    "\n",
    "  time_range=np.arange(-time_before,time_after)*5\n",
    "\n",
    "  for i in range(time_before,len(df['AR'])-time_after):\n",
    "    if intra_only:\n",
    "      if ret_list[i-1]==0 and ret_list[i+1]==0:\n",
    "        continue\n",
    "    if news_pos_list[i]==1:\n",
    "      j=i\n",
    "      k=i-1\n",
    "      before_list=[]\n",
    "      while (len(before_list)<time_before):\n",
    "        if ret_list[j-1]!=0:\n",
    "          before_list.append(AR_list[j-1])\n",
    "          j-=1\n",
    "        else:\n",
    "          while (ret_list[j-1]==0):\n",
    "            j-=1\n",
    "          before_list.append(AR_list[j-1])\n",
    "          before_list=before_list[::-1]\n",
    "      after_list=[]\n",
    "      while (len(after_list)<time_after):\n",
    "        if ret_list[k+1]!=0:\n",
    "          after_list.append(AR_list[k+1])\n",
    "          k+=1\n",
    "        else:\n",
    "          while (ret_list[k+1]==0):\n",
    "            k+=1\n",
    "          after_list.append(AR_list[k+1])\n",
    "      CAR_pos.append(np.cumsum(before_list+after_list))\n",
    "      # CAR.append(np.cumsum(AR_list[i-time_before:i+time_after]))\n",
    "    if news_neg_list[i]==1:\n",
    "      j=i\n",
    "      k=i-1\n",
    "      before_list=[]\n",
    "      while (len(before_list)<time_before):\n",
    "        if ret_list[j-1]!=0:\n",
    "          before_list.append(AR_list[j-1])\n",
    "          j-=1\n",
    "        else:\n",
    "          while (ret_list[j-1]==0):\n",
    "            j-=1\n",
    "          before_list.append(AR_list[j-1])\n",
    "          before_list=before_list[::-1]\n",
    "      after_list=[]\n",
    "      while (len(after_list)<time_after):\n",
    "        if ret_list[k+1]!=0:\n",
    "          after_list.append(AR_list[k+1])\n",
    "          k+=1\n",
    "        else:\n",
    "          while (ret_list[k+1]==0):\n",
    "            k+=1\n",
    "          after_list.append(AR_list[k+1])\n",
    "      CAR_neg.append(np.cumsum(before_list+after_list))\n",
    "      # CAR.append(np.cumsum(AR_list[i-time_before:i+time_after]))\n",
    "    if news_neu_list[i]==1:\n",
    "      j=i\n",
    "      k=i-1\n",
    "      before_list=[]\n",
    "      while (len(before_list)<time_before):\n",
    "        if ret_list[j-1]!=0:\n",
    "          before_list.append(AR_list[j-1])\n",
    "          j-=1\n",
    "        else:\n",
    "          while (ret_list[j-1]==0):\n",
    "            j-=1\n",
    "          before_list.append(AR_list[j-1])\n",
    "          before_list=before_list[::-1]\n",
    "      after_list=[]\n",
    "      while (len(after_list)<time_after):\n",
    "        if ret_list[k+1]!=0:\n",
    "          after_list.append(AR_list[k+1])\n",
    "          k+=1\n",
    "        else:\n",
    "          while (ret_list[k+1]==0):\n",
    "            k+=1\n",
    "          after_list.append(AR_list[k+1])\n",
    "      CAR_neu.append(np.cumsum(before_list+after_list))\n",
    "      # CAR.append(np.cumsum(AR_list[i-time_before:i+time_after]))\n",
    "  return CAR_pos, CAR_neg,CAR_neu, news, df   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OR_d5VkyfIje"
   },
   "source": [
    "## 4.1.2. By each group of news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zEfqE4om2kVj"
   },
   "outputs": [],
   "source": [
    "def get_CAR_group(begin_time,end_time,symbol,group,time_before=20,time_after=20,intra_only=False):\n",
    "  \n",
    "  stock_twits_symbol_list=['GILD','REGN','ABBV','ABT','BCRX','BTI','PM','MO','TPB','NVAX','SNY']\n",
    "  stock_data_list=['gild','regn','abbv','abt','bcrx','bti','pm','mo','tpb','nvax','sny']\n",
    "  news_file_list=['remdesivir','regeneron','abbv','chloroquine','Biocryst','tobacco','tobacco','tobacco','tobacco','nvax','chloroquine']\n",
    "\n",
    "  news=pd.read_csv('data/{}_news.csv'.format(news_file_list[stock_twits_symbol_list.index(symbol)]))\n",
    "  news.set_index('TimeStamp',inplace=True)\n",
    "  news.index=pd.to_datetime(news.index)\n",
    "  news=news[news['Group']==group].resample('5Min').count()\n",
    "  \n",
    "  price=pd.read_csv('data/{}.csv'.format(stock_data_list[stock_twits_symbol_list.index(symbol)]))\n",
    "  price.date=pd.to_datetime(price.date)\n",
    "  price.set_index('date',inplace=True)\n",
    "  price.index=price.index.tz_localize(None)\n",
    "  price['return']=(price.close-price.close.shift(1))/price.close.shift(1)\n",
    "  price_fill=price['return'].resample('5Min').asfreq(fill_value=0).to_frame()\n",
    "\n",
    "  index_df=pd.read_csv('data/spy.csv')\n",
    "  index_df.date=pd.to_datetime(index_df.date)\n",
    "  index_df.set_index('date',inplace=True)\n",
    "  index_df.index=index_df.index.tz_localize(None)\n",
    "\n",
    "\n",
    "  index_filled=index_df['close'].resample('5Min').ffill().to_frame()\n",
    "  index_filled['return']=(index_filled.close-index_filled.close.shift(1))/index_filled.close.shift(1)\n",
    "\n",
    "  temp=price_fill['return'].to_frame()\n",
    "\n",
    "  df=temp[(temp.index>=begin_time) & (temp.index<=end_time) ]\n",
    "  df['news'] = df.index.to_series().map(news['Title'])\n",
    "\n",
    "  df.fillna(0,inplace=True)\n",
    "  \n",
    "  df['ret_index']=df.index.to_series().map(index_filled['return'])\n",
    "  df.dropna(inplace=True)\n",
    "\n",
    "  Y = df['return']\n",
    "  X = df['ret_index']\n",
    "  X = sm.add_constant(X)\n",
    "  model = sm.OLS(Y,X)\n",
    "  results = model.fit()\n",
    "  df['exp_ret']=results.params[0]+results.params[1]*df['ret_index']\n",
    "  df['AR']=df['return']-df['exp_ret']\n",
    "\n",
    "  CAR=[]\n",
    "  \n",
    "  AR_list=df['AR'].values\n",
    "  news_list=df['news'].values\n",
    "  \n",
    "  ret_list=df['return'].values\n",
    "\n",
    "  time_range=np.arange(-time_before,time_after)*5\n",
    "\n",
    "  for i in range(time_before,len(df['AR'])-time_after):\n",
    "    if intra_only:\n",
    "      if ret_list[i-1]==0 and ret_list[i+1]==0:\n",
    "        continue\n",
    "    if news_list[i]==1:\n",
    "      j=i\n",
    "      k=i-1\n",
    "      before_list=[]\n",
    "      while (len(before_list)<time_before):\n",
    "        if ret_list[j-1]!=0:\n",
    "          before_list.append(AR_list[j-1])\n",
    "          j-=1\n",
    "        else:\n",
    "          while (ret_list[j-1]==0):\n",
    "            j-=1\n",
    "          before_list.append(AR_list[j-1])\n",
    "          before_list=before_list[::-1]\n",
    "      after_list=[]\n",
    "      while (len(after_list)<time_after):\n",
    "        if ret_list[k+1]!=0:\n",
    "          after_list.append(AR_list[k+1])\n",
    "          k+=1\n",
    "        else:\n",
    "          while (ret_list[k+1]==0):\n",
    "            k+=1\n",
    "          after_list.append(AR_list[k+1])\n",
    "      CAR.append(np.cumsum(before_list+after_list))\n",
    "      # CAR.append(np.cumsum(AR_list[i-time_before:i+time_after]))\n",
    "\n",
    "  return CAR, news, df   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4X5eKKCafTU_"
   },
   "source": [
    "## 4.2. Analysis based only on news happened during the trading time\n",
    "Here we only focus on the news that release during the trading time in US."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3gH55XcFfXrA"
   },
   "source": [
    "## 4.2.1. CAR for each stock\n",
    "By changing the symbol value in the symbol list \"stock_twits_symbol_list\", we can get the CAR of positive, negative and neutral news of that specific stocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jVniSxAXdVAf"
   },
   "outputs": [],
   "source": [
    "begin_time=dt(2020,1,14)\n",
    "end_time=dt(2020,5,2)\n",
    "stock_twits_symbol_list=['GILD','REGN','ABBV','ABT','BCRX','BTI','PM','MO','TPB','NVAX','SNY']\n",
    "symbol='GILD'\n",
    "\n",
    "time_before=20\n",
    "time_after=20\n",
    "time_range=np.arange(-time_before,time_after)*5\n",
    "\n",
    "CAR_pos,CAR_neg, CAR_neu, news, df = get_CAR(begin_time,end_time,symbol,local_news=True,intra_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uzXlg9Q4jc6t"
   },
   "source": [
    "### 4.2.1.1 CAR of positive news\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "colab_type": "code",
    "id": "a2WeKBmmYf4U",
    "outputId": "e54870dc-3382-4c73-dcde-93a55f47bbe6"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for i in range(len(CAR_pos)):\n",
    "  plt.plot(time_range,CAR_pos[i],label='{}'.format(i))\n",
    "plt.legend()\n",
    "plt.title('CAR of Positive news of {}'.format(symbol))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9fOnWgQzji18"
   },
   "source": [
    "### 4.2.1.2. CAR of negative news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "colab_type": "code",
    "id": "uhqLLCy4EhFO",
    "outputId": "5062874a-26e9-47c0-d3ec-f11274b3d043"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for i in range(len(CAR_neg)):\n",
    "# for i in range(5,10):\n",
    "  plt.plot(time_range,CAR_neg[i],label='{}'.format(i))\n",
    "plt.legend()\n",
    "plt.title('CAR of Negative news of {}'.format(symbol))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bvbz-7LGjl85"
   },
   "source": [
    "### 4.2.1.3. CAR of neutral news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "colab_type": "code",
    "id": "w7G6K5zyECLk",
    "outputId": "1cdf0b18-2759-4707-cd6d-157b3473ffba"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for i in range(len(CAR_neu)):\n",
    "  plt.plot(time_range,CAR_neu[i],label='{}'.format(i))\n",
    "plt.legend()\n",
    "plt.title('CAR of Neutral news of {}'.format(symbol))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ca-hO3_afb39"
   },
   "source": [
    "## 4.2.2. CAR for positive, negative or neutral news\n",
    "This part show the average CAR of all the studied stocks based on positive, negative and neutral news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "YtgS2hY9YP3b",
    "outputId": "fa410021-502b-41c5-bc9d-e9f685a0ae2c"
   },
   "outputs": [],
   "source": [
    "stock_twits_symbol_list=['GILD','REGN','ABBV','ABT','BCRX','BTI','PM','MO','TPB','NVAX','SNY']\n",
    "begin_time=dt(2020,1,14)\n",
    "end_time=dt(2020,5,2)\n",
    "intra_only=True\n",
    "\n",
    "all_CAR_pos=[]\n",
    "all_CAR_neg=[]\n",
    "all_CAR_neu=[]\n",
    "for symbol in tqdm(stock_twits_symbol_list):\n",
    "  CAR_pos,CAR_neg, CAR_neu, news, df = get_CAR(begin_time,end_time,symbol,local_news=True,intra_only=intra_only)\n",
    "  all_CAR_pos = all_CAR_pos + CAR_pos\n",
    "  all_CAR_neg = all_CAR_neg + CAR_neg\n",
    "  all_CAR_neu = all_CAR_neu + CAR_neu\n",
    "all_CAR_pos=np.array(all_CAR_pos)\n",
    "all_CAR_neg=np.array(all_CAR_neg)\n",
    "all_CAR_neu=np.array(all_CAR_neu)\n",
    "mean_CAR_pos = np.mean(all_CAR_pos,axis=0)\n",
    "mean_CAR_neg = np.mean(all_CAR_neg,axis=0)\n",
    "mean_CAR_neu = np.mean(all_CAR_neu,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "colab_type": "code",
    "id": "vN-idYwUcNvA",
    "outputId": "81b370df-bf1c-4f5d-e060-c29dc63a4338"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(time_range,np.mean(all_CAR_pos,axis=0),label='Positive')\n",
    "plt.plot(time_range,np.mean(all_CAR_neg,axis=0),label='Negative')\n",
    "plt.plot(time_range,np.mean(all_CAR_neu,axis=0),label='Neutral')\n",
    "plt.legend()\n",
    "plt.title('Average CAR for all stock')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IsJEvceffnyu"
   },
   "source": [
    "## 4.2.3. CAR by group of news\n",
    "This part shows the CAR of all studied stocks based on each type of news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lBwKd9Pl2_fg"
   },
   "outputs": [],
   "source": [
    "begin_time=dt(2020,1,14)\n",
    "end_time=dt(2020,5,2)\n",
    "group_list=['Trial','Approval','Positive result','Negative result','Supply','Speculation','Side effects','Partnership','Other']\n",
    "stock_twits_symbol_list=['GILD','REGN','ABBV','ABT','BCRX','BTI','PM','MO','TPB','NVAX','SNY']\n",
    "intra_only=True\n",
    "\n",
    "def get_plot_group(begin_time,end_time,group,intra_only):\n",
    "  all_CAR=[]\n",
    "  for symbol in stock_twits_symbol_list:\n",
    "    CAR, news, df = get_CAR_group(begin_time,end_time,symbol,group,intra_only=intra_only)\n",
    "    all_CAR = all_CAR + CAR\n",
    "  all_CAR=np.array(all_CAR)\n",
    "  mean_CAR = np.mean(all_CAR,axis=0)\n",
    "  return all_CAR, mean_CAR \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-Lmzyk5skMo_"
   },
   "source": [
    "### Graphs of CAR by each group of news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Gec_2AyL7q4H",
    "outputId": "cc7adc39-bd08-41f6-f74a-0602e341d35a"
   },
   "outputs": [],
   "source": [
    "for group in tqdm(group_list):\n",
    "  all_CAR, mean_CAR=get_plot_group(begin_time,end_time,group,intra_only=intra_only)\n",
    "  \n",
    "  plt.figure(figsize=(8, 5))\n",
    "  plt.title('All CAR of {} news'.format(group))\n",
    "  for i in range(len(all_CAR)):\n",
    "    plt.plot(time_range,all_CAR[i])\n",
    "  plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VfrJoSwtkXO8"
   },
   "source": [
    "### Average CAR by each group of news\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 615
    },
    "colab_type": "code",
    "id": "OkT4ztwdA3iy",
    "outputId": "75fe6068-da46-4a2b-ae69-37483b28300a"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "plt.title('Mean CAR of {} news'.format(group))\n",
    "for group in tqdm(group_list):\n",
    "  all_CAR, mean_CAR=get_plot_group(begin_time,end_time,group,intra_only=intra_only)\n",
    "  try:  \n",
    "    plt.plot(time_range,mean_CAR,label='{}'.format(group))\n",
    "  except:\n",
    "    pass\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n_Iz9Aldkm3N"
   },
   "source": [
    "# 4.2.3. Analysis based on all news"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jm87Fhprkm3O"
   },
   "source": [
    "## 4.2.3.1 CAR for each stock\n",
    "By changing the symbol value in the symbol list \"stock_twits_symbol_list\", we can get the CAR of positive, negative and neutral news of that specific stocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6iiM2cLhkm3O"
   },
   "outputs": [],
   "source": [
    "begin_time=dt(2020,1,14)\n",
    "end_time=dt(2020,5,2)\n",
    "stock_twits_symbol_list=['GILD','REGN','ABBV','ABT','BCRX','BTI','PM','MO','TPB','NVAX','SNY']\n",
    "symbol='GILD'\n",
    "intra_only=False\n",
    "\n",
    "time_before=20\n",
    "time_after=20\n",
    "time_range=np.arange(-time_before,time_after)*5\n",
    "\n",
    "CAR_pos,CAR_neg, CAR_neu, news, df = get_CAR(begin_time,end_time,symbol,local_news=True,intra_only=intra_only)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oCuctdjxkm3R"
   },
   "source": [
    "### CAR of positive news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "colab_type": "code",
    "id": "Q1ErPCQjkm3S",
    "outputId": "4cad7ba3-b50e-40de-cb50-6eec683e7d10"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for i in range(len(CAR_pos)):\n",
    "  plt.plot(time_range,CAR_pos[i],label='{}'.format(i))\n",
    "plt.legend()\n",
    "plt.title('CAR of Positive news of {}'.format(symbol))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lHOa0yyBkm3W"
   },
   "source": [
    "### CAR of negative news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "colab_type": "code",
    "id": "cqs2jFtjkm3X",
    "outputId": "0bf9a974-0a8d-4c66-e422-c4e852be0625"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for i in range(len(CAR_neg)):\n",
    "# for i in range(5,10):\n",
    "  plt.plot(time_range,CAR_neg[i],label='{}'.format(i))\n",
    "plt.legend()\n",
    "plt.title('CAR of Negative news of {}'.format(symbol))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uFjH6mtWkm3Z"
   },
   "source": [
    "### CAR of neutral news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "colab_type": "code",
    "id": "7bh_Kgmbkm3Z",
    "outputId": "89ce82db-4e43-460e-d128-472ded2b8a37"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for i in range(len(CAR_neu)):\n",
    "  plt.plot(time_range,CAR_neu[i],label='{}'.format(i))\n",
    "plt.legend()\n",
    "plt.title('CAR of Neutral news of {}'.format(symbol))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OVY5X640km3b"
   },
   "source": [
    "## 4.2.3.2. CAR for positive, negative or neutral news\n",
    "This part show the average CAR of all the studied stocks based on positive, negative and neutral news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "hpXrnszDkm3b",
    "outputId": "00097952-b263-4e84-a3bb-a984b808992d"
   },
   "outputs": [],
   "source": [
    "stock_twits_symbol_list=['GILD','REGN','ABBV','ABT','BCRX','BTI','PM','MO','TPB','NVAX','SNY']\n",
    "begin_time=dt(2020,1,14)\n",
    "end_time=dt(2020,5,2)\n",
    "intra_only=False\n",
    "\n",
    "all_CAR_pos=[]\n",
    "all_CAR_neg=[]\n",
    "all_CAR_neu=[]\n",
    "for symbol in tqdm(stock_twits_symbol_list):\n",
    "  CAR_pos,CAR_neg, CAR_neu, news, df = get_CAR(begin_time,end_time,symbol,local_news=True,intra_only=intra_only)\n",
    "  all_CAR_pos = all_CAR_pos + CAR_pos\n",
    "  all_CAR_neg = all_CAR_neg + CAR_neg\n",
    "  all_CAR_neu = all_CAR_neu + CAR_neu\n",
    "all_CAR_pos=np.array(all_CAR_pos)\n",
    "all_CAR_neg=np.array(all_CAR_neg)\n",
    "all_CAR_neu=np.array(all_CAR_neu)\n",
    "mean_CAR_pos = np.mean(all_CAR_pos,axis=0)\n",
    "mean_CAR_neg = np.mean(all_CAR_neg,axis=0)\n",
    "mean_CAR_neu = np.mean(all_CAR_neu,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "colab_type": "code",
    "id": "GPi-dz_Zkm3d",
    "outputId": "dfb45572-15b0-4766-f3f6-ceaf647e1e68"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(time_range,np.mean(all_CAR_pos,axis=0),label='Positive')\n",
    "plt.plot(time_range,np.mean(all_CAR_neg,axis=0),label='Negative')\n",
    "plt.plot(time_range,np.mean(all_CAR_neu,axis=0),label='Neutral')\n",
    "plt.legend()\n",
    "plt.title('Average CAR for all stock')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mdhixk7mkm3f"
   },
   "source": [
    "## 4.2.3.3. CAR by group of news\n",
    "This part shows the CAR of all studied stocks based on each type of news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OMOlxTFvkm3g"
   },
   "outputs": [],
   "source": [
    "begin_time=dt(2020,1,14)\n",
    "end_time=dt(2020,5,2)\n",
    "group_list=['Trial','Approval','Positive result','Negative result','Supply','Speculation','Side effects','Partnership','Other']\n",
    "stock_twits_symbol_list=['GILD','REGN','ABBV','ABT','BCRX','BTI','PM','MO','TPB','NVAX','SNY']\n",
    "intra_only=False\n",
    "\n",
    "def get_plot_group(begin_time,end_time,group,intra_only):\n",
    "  all_CAR=[]\n",
    "  for symbol in stock_twits_symbol_list:\n",
    "    CAR, news, df = get_CAR_group(begin_time,end_time,symbol,group,intra_only=intra_only)\n",
    "    all_CAR = all_CAR + CAR\n",
    "  all_CAR=np.array(all_CAR)\n",
    "  mean_CAR = np.mean(all_CAR,axis=0)\n",
    "  return all_CAR, mean_CAR \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qq-s7fskkm3j"
   },
   "source": [
    "### Graphs of CAR by each group of news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "ufz1wY70km3k",
    "outputId": "44e25967-fad2-4a71-a9c3-a6d0f2e3a7b7"
   },
   "outputs": [],
   "source": [
    "for group in tqdm(group_list):\n",
    "  all_CAR, mean_CAR=get_plot_group(begin_time,end_time,group,intra_only=intra_only)\n",
    "  \n",
    "  plt.figure(figsize=(8, 5))\n",
    "  plt.title('All CAR of {} news'.format(group))\n",
    "  for i in range(len(all_CAR)):\n",
    "    plt.plot(time_range,all_CAR[i])\n",
    "  plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0FUki6jgkm3m"
   },
   "source": [
    "### Average CAR by each group of news\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 461
    },
    "colab_type": "code",
    "id": "CeCKYXQ7km3m",
    "outputId": "c5dc8f3e-f95b-4c9c-c68e-e5ea8119d8f5"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "plt.title('Mean CAR of {} news'.format(group))\n",
    "for group in tqdm(group_list):\n",
    "  all_CAR, mean_CAR=get_plot_group(begin_time,end_time,group,intra_only=intra_only)\n",
    "  try:  \n",
    "    plt.plot(time_range,mean_CAR,label='{}'.format(group))\n",
    "  except:\n",
    "    pass\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xXBT03lVk9aZ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Covid_19.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
